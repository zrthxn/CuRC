{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651c41d9-420a-4e96-af86-0ccfa1fcd7b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <center><font color=navy> Tutorial #4 Computer- and robot-assisted surgery</font></center>\n",
    "## <center><font color=navy> Tomography II</font></center>\n",
    "<center>&copy; Sebastian Bodenstedt, National Center for Tumor Diseases (NCT) Dresden<br>\n",
    "    <a href=\"https://www.nct-dresden.de/\"><img src=\"https://www.nct-dresden.de/++theme++nct/images/logo-nct-en.svg\"></a> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a39e8-11e2-4924-9b39-76590ee4a258",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Preperation</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6b125-ddac-45d1-9bca-b1ff36588acf",
   "metadata": {},
   "source": [
    "For this tutorial, we will utilize the OpenCV, Matplotlib and NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15771f22-b5e5-4a26-9ff5-3a6285d6d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install numpy, opencv and matplot-lib pip packages into the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy opencv-python matplotlib matplotlib-inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb072f65-e316-4971-af26-99319c4584c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Force Matplotlib to display data directly in Jupyter\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.interpolate\n",
    "from scipy import ndimage\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064408b2-2803-49b3-ac0c-c2e2f190d735",
   "metadata": {},
   "source": [
    "We will also download and extract a few image sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1f45c-9c7a-4d5f-a3a9-32e76298d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from os.path import basename, exists\n",
    "import zipfile\n",
    "\n",
    "def download_and_extract(url): #download and extract Zip archive\n",
    "    file_path = basename(url)\n",
    "    if not exists(file_path): # does zip file already exist?\n",
    "        urllib.request.urlretrieve(url, file_path) # if not, download it\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref: # and unzip it\n",
    "            zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94bfb6-1886-4889-ac54-095702a2093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract(\"http://tso.ukdd.de/crs/TomographyII.zip\") # In case you didn't download the data last week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da43280-1dfc-4da7-847f-6d1fc6b29ad3",
   "metadata": {},
   "source": [
    "We now list the extracted files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4538ff-1119-4562-9395-7a9f279d37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e2ce0-3e57-4585-b6f6-19f26f5fee66",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Basic functions</font></center>\n",
    "We define a function for displaying grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18739d94-3631-4a09-80db-32cd319fb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gray(img, canvas=plt, title=\"\"): # Later we want to draw on a different underground, so we define this as a parameter\n",
    "    canvas.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    if not title == \"\":\n",
    "        canvas.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555b460-ebb8-40ff-bf54-28187792a393",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Review image loading and rotation</font></center>\n",
    "First, we develop a method to rotate 2D images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c42d3b-41a9-446d-a564-80438f94aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image in grayscale\n",
    "#img_gray = cv2.imread(\"Exercise2/Example.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "#img_gray = cv2.imread(\"Exercise3/img_01_raw.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img_gray = cv2.imread(\"TomographyII/maulwurf.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Make sure image is square\n",
    "size = min(img_gray.shape[0],img_gray.shape[1])\n",
    "img_gray = img_gray[:size,:size]\n",
    "\n",
    "figure, axis = plt.subplots(1, 2, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "\n",
    "show_gray(img_gray, axis[0])\n",
    "\n",
    "img_rot2 = ndimage.rotate(img_gray, 45)\n",
    "\n",
    "show_gray(img_rot2, axis[1])\n",
    "print(img_gray.shape, img_rot2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7960e-7a21-4d29-a0eb-5150297489c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 4, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "\n",
    "show_gray(img_gray, axis[0])\n",
    "\n",
    "shape = img_gray.shape\n",
    "\n",
    "img_rot = ndimage.rotate(img_gray, 45)\n",
    "\n",
    "show_gray(img_rot, axis[1])\n",
    "\n",
    "img_rot_back = ndimage.rotate(img_rot, -45)\n",
    "\n",
    "show_gray(img_rot_back, axis[2])\n",
    "\n",
    "offset_y = (img_rot_back.shape[0] - shape[0])//2 # Find Center of image\n",
    "offset_x = (img_rot_back.shape[1] - shape[1])//2\n",
    "         \n",
    "img_rot_back_crop = img_rot_back[offset_y:offset_y + shape[0],offset_x:offset_x + shape[0]] # Crop result and apply it to output\n",
    "show_gray(img_rot_back_crop, axis[3])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a7c16-084a-4d06-9f54-c9f026f2cdc5",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Fourier Transformation in NumPy</font></center>\n",
    "Reminder, we can represent an image by the frequencies it contains, using the Fourier Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e01ca-f6dc-44d3-972c-535c7557008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = np.fft.fft2(img_gray) # 2D fourier transform of our image\n",
    "ft_centered = np.fft.fftshift(ft) # shift the transform, so the origin is in the center of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180f325-ab12-4f9e-8ec8-b9d9058c63b7",
   "metadata": {},
   "source": [
    "We can visualize the spectrum of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948c416-c037-42c8-abb5-9a98915f6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.log(abs(ft_centered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43b5ce-71b7-4505-99c9-5fcd054b0f6a",
   "metadata": {},
   "source": [
    "And we can also reverse the Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c2fae-de60-44aa-be08-e502e5827823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ift = np.fft.ifftshift(ft_centered) # Reverse shift\n",
    "ift = np.fft.ifft2(ift) # Inverse Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0083c5-0ba4-40a9-85c0-e1598eb440cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 3, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "axis[0].imshow(img_gray, cmap='gray')\n",
    "axis[1].imshow(spec, cmap='gray')\n",
    "axis[2].imshow(np.real(ift), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ba3ca-bd2a-4817-bce1-14b21500eb73",
   "metadata": {},
   "source": [
    "You can modify the spectrum using image manipulation. One way is to create a mask and apply it to the spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f6da4-0d64-4677-8357-7cbe3ef0ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 50\n",
    "\n",
    "mask = np.zeros(ft_centered.shape, dtype=np.uint8) # Create an empty image\n",
    "mask = cv2.circle(mask, (ft_centered.shape[0]//2, ft_centered.shape[0]//2), radius,1,-1) # Draw a circle\n",
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6b505-0d97-4b88-9347-6f47249f2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_centered_mod = ft_centered.copy()\n",
    "ft_centered_mod[mask == 0] = 0 # set frequencies outside circle to 0\n",
    "\n",
    "spec_mod = np.log(abs(ft_centered_mod))\n",
    "figure, axis = plt.subplots(1, 2, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "axis[0].imshow(spec, cmap='gray')\n",
    "axis[1].imshow(spec_mod, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c659b-70f0-4944-a98f-cf3f4eb403e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ift = np.fft.ifftshift(ft_centered_mod)\n",
    "ift = np.fft.ifft2(ift)\n",
    "\n",
    "figure, axis = plt.subplots(1, 2, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "show_gray(img_gray, axis[0])\n",
    "axis[1].imshow(np.real(ift), cmap='gray')\n",
    "print(np.min(np.real(ift)), np.max(np.real(ift)), np.mean(np.real(ift)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578f5ad-cda5-412b-afde-15c2de6c91cc",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Simulated CT</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76479d65-3258-4e1c-af9e-55193e449196",
   "metadata": {},
   "source": [
    "Next, we simulate the projection step of a CT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b50ebf-72a6-4779-8bdd-21774b6b9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_proj(image, step_size):\n",
    "    assert image.shape[0] == image.shape[1] # check if images are square\n",
    "    num_steps = 180//step_size # Calculate the number of steps\n",
    "    diag = round(math.sqrt(2*image.shape[0]*image.shape[0])) # calculate diagonal of the image, i.e. the maximum number of pixels when rotated 45 degrees\n",
    "    print(diag)\n",
    "    \n",
    "    projections = np.zeros((num_steps, diag), dtype=np.float64) # Setup container for all projections\n",
    "    \n",
    "    count = 0\n",
    "    for angle in range(0, 180, step_size):\n",
    "        rot_image = ndimage.rotate(image, angle) # Rotate image\n",
    "        proj = np.sum(rot_image, axis=0) # Calculate projection by adding values along axis 0\n",
    "        \n",
    "        projections[count, 0:rot_image.shape[0]] = proj # save projection\n",
    "        count+=1\n",
    "    \n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47178f57-e019-4ebe-be8a-39a3a3457d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = 1 # Step size\n",
    "projs = calc_proj(img_gray, degrees) # Calculate projections\n",
    "shape = img_gray.shape\n",
    "print(projs.shape)\n",
    "data = {\"projections\" : projs, \"shape\" : shape, \"step_size\" : degrees}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1f067-8911-46c3-a1d6-36d965f1fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump( data, open( \"TomographyII/output.pkl\", \"wb\" ) ) #Save projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a542a1e-519b-48a1-9cf9-41758907e642",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Reconstruction with Fourier</font></center>\n",
    "First, we load the mystery image from last time that was encoded with the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f9d18-8f13-4693-9171-ea80940f21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"TomographyII/output.pkl\", \"rb\" ) ) # Load a secret\n",
    "\n",
    "step_size = data[\"step_size\"]\n",
    "projs = data[\"projections\"]\n",
    "shape = data[\"shape\"]\n",
    "\n",
    "print(step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbe71c-b6af-4775-ad0d-7835df6cd525",
   "metadata": {},
   "source": [
    "Now, we will reconstruct the image using the Radon Transformation/Fourier Slice Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cff9f3-9d7f-4651-acb8-4cfed206853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(input_proj, step_size, output_shape):\n",
    "    \"\"\"\n",
    "    Reconstructs an image from CT projections using the back-projection method.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_proj: numpy array containing the projections (shape: num_projections x projection_length).\n",
    "    - step_size: int, angle step size in degrees for each projection.\n",
    "    - output_shape: tuple, shape of the output 2D reconstructed image.\n",
    "    \n",
    "    Returns:\n",
    "    - 2D numpy array representing the reconstructed image in the Fourier domain.\n",
    "    \"\"\"\n",
    "    # Initialize the output image as a complex array\n",
    "    output = np.zeros(output_shape, dtype=np.complex64)\n",
    "    # Create an empty mask for rotation purposes (not used in computation but for reference)\n",
    "    mask = np.zeros(output_shape, dtype=np.int64)\n",
    "\n",
    "    # Process each projection at the specified angle increment\n",
    "    for count, angle in enumerate(range(0, 180, step_size)):\n",
    "        # Rotate the mask to the current angle (used for determining rotation size)\n",
    "        rotated_mask = scipy.ndimage.rotate(mask, angle)\n",
    "        # Create a blank rotated image with the same shape as the rotated mask\n",
    "        rotated_image = np.zeros(rotated_mask.shape, dtype=np.complex64)\n",
    "\n",
    "        # Extract the current projection and apply the 1D Fourier Transform\n",
    "        projection = input_proj[count, :rotated_image.shape[0]]\n",
    "        ft_projection = np.fft.fftshift(np.fft.fft(np.fft.ifftshift(projection)))\n",
    "\n",
    "        # Place the Fourier transform result in the center row of the rotated image\n",
    "        rotated_image[rotated_image.shape[0] // 2] = ft_projection\n",
    "\n",
    "        # Rotate the image back to its original orientation\n",
    "        rotated_back_image = ndimage.rotate(rotated_image, -angle)\n",
    "\n",
    "        # Calculate the offset for cropping the rotated image to match the output shape\n",
    "        offset_y = (rotated_back_image.shape[0] - output_shape[0]) // 2\n",
    "        offset_x = (rotated_back_image.shape[1] - output_shape[1]) // 2\n",
    "\n",
    "        # Crop the image and add it to the output\n",
    "        output += rotated_back_image[offset_y:offset_y + output_shape[0], offset_x:offset_x + output_shape[1]]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c1cfa-b55a-4457-9231-c808d5c6b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = reconstruction(projs, step_size, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df195661-4655-4bc2-b780-5e62db727c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = np.real(np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(res))))\n",
    "\n",
    "plt.imshow(res2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6cd1dc-cbb8-4f80-a3cd-40b6ea174a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_mod = np.log(abs(res))\n",
    "figure, axis = plt.subplots(1, 2, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "\n",
    "axis[0].imshow(spec_mod, cmap='gray')\n",
    "axis[1].imshow(spec, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693b58e-6fee-48b6-8285-7c2a1c642206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction2(input_proj, step_size, output_shape):\n",
    "    \"\"\"\n",
    "    Reconstructs a 2D Fourier Transform from CT projections.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_proj: numpy array of shape (num_projections, projection_length) containing CT projections.\n",
    "    - step_size: int, angle step size in degrees for each projection.\n",
    "    - output_shape: tuple, shape of the output 2D reconstructed image.\n",
    "    \n",
    "    Returns:\n",
    "    - 2D numpy array representing the reconstructed Fourier Transform.\n",
    "    \"\"\"\n",
    "    # Generate an empty mask of ones for rotation reference\n",
    "    mask = np.ones(output_shape, dtype=np.int64)\n",
    "\n",
    "    # Initialize lists to store source coordinates and Fourier transform values\n",
    "    src_x_coords = []\n",
    "    src_y_coords = []\n",
    "    fft_values = []\n",
    "\n",
    "    # Process each projection at the specified step size\n",
    "    for idx, angle in enumerate(range(0, 180, step_size)):\n",
    "        # Convert the current angle to radians\n",
    "        rad_angle = np.deg2rad(angle)\n",
    "\n",
    "        # Rotate the mask to align with the current angle (used for coordinate mapping)\n",
    "        rotated_mask = scipy.ndimage.rotate(mask, angle)\n",
    "        num_points = rotated_mask.shape[0]\n",
    "\n",
    "        # Calculate the source coordinates for the rotated mask\n",
    "        center_offset = (np.arange(num_points) - num_points / 2) / num_points * output_shape[0]\n",
    "        src_x = (output_shape[0] / 2) + center_offset * np.cos(rad_angle)\n",
    "        src_y = (output_shape[0] / 2) + center_offset * np.sin(rad_angle)\n",
    "\n",
    "        # Append the calculated coordinates to the lists\n",
    "        src_x_coords.append(src_x)\n",
    "        src_y_coords.append(src_y)\n",
    "\n",
    "        # Get the current projection and compute its 1D Fourier Transform\n",
    "        projection = input_proj[idx, :num_points]\n",
    "        transformed_projection = np.fft.fftshift(np.fft.fft(np.fft.ifftshift(projection)))\n",
    "\n",
    "        # Store the Fourier transform values\n",
    "        fft_values.append(transformed_projection)\n",
    "\n",
    "    # Combine all coordinates and Fourier transform values into flat arrays\n",
    "    src_x_coords = np.concatenate(src_x_coords)\n",
    "    src_y_coords = np.concatenate(src_y_coords)\n",
    "    fft_values = np.concatenate(fft_values)\n",
    "\n",
    "    # Create a grid for the output image coordinates\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(output_shape[0]), np.arange(output_shape[0]))\n",
    "    grid_x_flat = grid_x.flatten()\n",
    "    grid_y_flat = grid_y.flatten()\n",
    "\n",
    "    # Interpolate the Fourier transform values onto the output grid\n",
    "    reconstructed_fft = scipy.interpolate.griddata(\n",
    "        (src_x_coords, src_y_coords),\n",
    "        fft_values,\n",
    "        (grid_x_flat, grid_y_flat),\n",
    "        method='linear',\n",
    "        fill_value=0.0\n",
    "    ).reshape(output_shape)\n",
    "\n",
    "    return reconstructed_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5bc24-88e6-4fcc-8a8d-c6db79b1a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = reconstruction2(projs, step_size, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d348d3f-e85b-4fc0-b27b-18c5ac24c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_mod = np.log(abs(res))\n",
    "figure, axis = plt.subplots(1, 2, figsize=(15, 15)) # subplots let you visualize multiple outputs simultanously\n",
    "axis[0].imshow(spec, cmap='gray')\n",
    "axis[1].imshow(spec_mod, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855214b-ce49-4721-a4d9-a82fd00edc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = np.real(np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(res))))\n",
    "\n",
    "show_gray(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c49a4-4a09-40b0-94df-b6a758bfb779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
